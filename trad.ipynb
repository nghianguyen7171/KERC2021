{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os.path\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from joblib import dump\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_with_sampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "label_dict = {'HAHV': 0, 'HALV': 1, 'LALV': 2, 'LAHV': 3}\n",
    "\n",
    "\n",
    "def parse_id_signals(path, id):\n",
    "    signals = ['BVP', 'EDA', 'EEG_ftrs']\n",
    "    ret = {}\n",
    "    for sgn in signals:\n",
    "        ret[sgn] = np.load(os.path.join(path, '{}_{}.npy'.format(id, sgn)))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Loading data for using with traditional machine learning methods\n",
    "    :param path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    data_loaders = {}\n",
    "    for dt in ['train', 'val', 'test']:\n",
    "        data_loaders[dt] = {}\n",
    "        list_ids = np.loadtxt(os.path.join(path, '{}_ids.txt'.format(dt)), dtype=str)\n",
    "        if dt == 'train':\n",
    "            list_labels = pd.read_csv(os.path.join(path, 'train_labels.csv'))\n",
    "            list_labels.sort_values('Id', inplace=True)\n",
    "            assert np.sum(list_labels['Id'].values != list_ids) == 0\n",
    "            labels_data = list_labels.values[:, 1]\n",
    "        else:\n",
    "            labels_data = -1 * np.ones(len(list_ids))\n",
    "\n",
    "        personality = pd.read_csv(os.path.join(path, '{}_personality.csv'.format(dt)))\n",
    "        personality.sort_values('Id', inplace=True)\n",
    "        assert np.sum(personality['Id'].values != list_ids) == 0\n",
    "        personality_data = personality.values\n",
    "\n",
    "        data_loaders[dt]['id'] = []\n",
    "\n",
    "        for idx in range(len(list_ids)):\n",
    "            cur_id = list_ids[idx]\n",
    "            ret = parse_id_signals(os.path.join(path, dt), cur_id)\n",
    "            ret['personality'] = personality_data[idx, 1:]\n",
    "            if dt == 'train':\n",
    "                ret['label'] = label_dict[labels_data[idx]]\n",
    "            else:\n",
    "                ret['label'] = labels_data[idx]\n",
    "\n",
    "            data_loaders[dt]['id'].append(cur_id)\n",
    "            for fky in ret.keys():\n",
    "                if fky not in data_loaders[dt].keys():\n",
    "                    data_loaders[dt][fky] = []\n",
    "\n",
    "                data_loaders[dt][fky].append(ret[fky])\n",
    "\n",
    "        for fky in data_loaders[dt].keys():\n",
    "            data_loaders[dt][fky] = np.array(data_loaders[dt][fky])\n",
    "\n",
    "    merge_val_test = True\n",
    "    if merge_val_test:\n",
    "        for ky in data_loaders['test'].keys():\n",
    "            data_loaders['test'][ky] = np.concatenate([data_loaders['val'][ky], data_loaders['test'][ky]])\n",
    "        _ = data_loaders.pop('val')\n",
    "\n",
    "    return data_loaders\n",
    "\n",
    "\n",
    "def gridsearch_clf(x_train, y_train, model_name='svm'):\n",
    "    print('-------------------\\nGridsearch CV for {}'.format(model_name))\n",
    "    stt = time.time()\n",
    "    # cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=9999)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=999999)\n",
    "\n",
    "    if model_name == 'svm':\n",
    "        estimator = make_pipeline(StandardScaler(), PCA(),\n",
    "                                  SVC(decision_function_shape='ovr', class_weight='balanced', random_state=9999, probability=True))\n",
    "        # parameters = {'svc__kernel': ['linear', 'rbf'], 'svc__C': [1, 10, 100], 'svc__gamma': [1e-3, 1e-4, 1e-2]}\n",
    "        num_feats = x_train.shape[1]\n",
    "        parameters = [{'svc__kernel': ['rbf'], 'svc__C': np.logspace(-3, 5, num=10, endpoint=True, base=2.0),\n",
    "                       'svc__gamma': np.logspace(-7, 3, num=10, endpoint=True, base=2.0),\n",
    "                       'pca__n_components': np.random.randint(num_feats // 5, num_feats * 4 // 5, size=10),\n",
    "                       'pca__whiten': [True, False], 'pca__random_state': [9999]},\n",
    "                      ]\n",
    "    elif model_name == 'rf':\n",
    "        estimator = RandomForestClassifier(n_jobs=4, oob_score=True, warm_start=False)\n",
    "        # estimator = make_pipeline_with_sampler(RandomUnderSampler(), RandomForestClassifier(n_jobs=4))\n",
    "\n",
    "        parameters = {'n_estimators': np.random.randint(low=30, high=100, size=30),\n",
    "                      'max_features': ['sqrt', 'log2'],\n",
    "                      'criterion': ['gini', 'entropy'],\n",
    "                      'random_state': np.random.randint(0, 100, 10),\n",
    "                      'class_weight': ['balanced', 'balanced_subsample']}\n",
    "\n",
    "    elif model_name == 'adaboost':\n",
    "        DTC = DecisionTreeClassifier(class_weight='balanced', )\n",
    "        # estimator = AdaBoostClassifier(base_estimator=DTC)\n",
    "        estimator = make_pipeline_with_sampler(RandomUnderSampler(), AdaBoostClassifier(base_estimator=DTC))\n",
    "\n",
    "        parameters = {'randomundersampler__random_state': np.random.randint(0, 100, 10),\n",
    "                      'adaboostclassifier__n_estimators': np.random.randint(20, 50, 5),\n",
    "                      'adaboostclassifier__learning_rate': np.arange(1e-2, 2e-1, step=0.02),\n",
    "                      'adaboostclassifier__random_state': np.random.randint(0, 100, 10),\n",
    "                      'adaboostclassifier__base_estimator__random_state': np.random.randint(0, 100, 7),\n",
    "                      \"adaboostclassifier__base_estimator__criterion\": [\"gini\", \"entropy\"],\n",
    "                      \"adaboostclassifier__base_estimator__splitter\": [\"best\", \"random\"], }\n",
    "    else:\n",
    "        raise ValueError('Unkown estimator {}'.format(model_name))\n",
    "\n",
    "    clf = GridSearchCV(estimator=estimator, param_grid=parameters,\n",
    "                       scoring={'f1': 'f1_micro', 'acc': 'accuracy'}, n_jobs=-1, cv=cv,\n",
    "                       refit='f1')\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    print('Best score using {}: {}'.format(model_name, clf.best_score_))\n",
    "    print('Total time: {:5f} second'.format(time.time()-stt))\n",
    "    return clf\n",
    "\n",
    "\n",
    "def select_feat_type(data_loaders, feat_list=('eeg_ftrs',)):\n",
    "    ret_data = {}\n",
    "    for dt in ['train', 'test']:\n",
    "        ret_data[dt] = {}\n",
    "        sel_feat = []\n",
    "        for feat in feat_list:\n",
    "            sel_feat.append(data_loaders[dt][feat])\n",
    "\n",
    "        sel_feat = np.concatenate(sel_feat, axis=-1)\n",
    "        ret_data[dt]['feat'] = sel_feat\n",
    "        if dt == 'train':\n",
    "            ret_data[dt]['label'] = data_loaders[dt]['label']\n",
    "\n",
    "        ret_data[dt]['id'] = data_loaders[dt]['id']\n",
    "\n",
    "    return ret_data\n",
    "\n",
    "\n",
    "def prediction_2_csv(prediction, id, save_name):\n",
    "    list_cat = np.array(['HAHV', 'HALV', 'LALV', 'LAHV'])\n",
    "    write_pred = list_cat[prediction]\n",
    "    pd.DataFrame(np.stack([id, write_pred], axis=-1), columns=['Id', 'Predicted']).to_csv(save_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save folder:  /home/nghia/PR_LAB/KERC_Chall/kerc2021/KERC21Baseline/KERC21Baseline/train_logs/11-02-2021_00-05-22/11-02-2021_00-05-22\n",
      "-------------------\n",
      "Gridsearch CV for svm\n",
      "Best score using svm: 0.6036231884057971\n",
      "Total time: 248.340766 second\n",
      "EEG_ftrs \n",
      " {'pca__n_components': 229, 'pca__random_state': 9999, 'pca__whiten': False, 'svc__C': 9.332232316608927, 'svc__gamma': 0.0078125, 'svc__kernel': 'rbf'}\n",
      "-------------------\n",
      "Gridsearch CV for rf\n",
      "Best score using rf: 0.5710144927536231\n",
      "Total time: 431.304775 second\n",
      "EEG_ftrs \n",
      " {'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 99, 'random_state': 13}\n",
      "-------------------\n",
      "Gridsearch CV for svm\n",
      "Best score using svm: 0.44999999999999996\n",
      "Total time: 100.509004 second\n",
      "BVP \n",
      " {'pca__n_components': 11, 'pca__random_state': 9999, 'pca__whiten': True, 'svc__C': 2.7215800003487542, 'svc__gamma': 0.7937005259840999, 'svc__kernel': 'rbf'}\n",
      "-------------------\n",
      "Gridsearch CV for svm\n",
      "Best score using svm: 0.4268115942028985\n",
      "Total time: 91.067334 second\n",
      "EDA \n",
      " {'pca__n_components': 3, 'pca__random_state': 9999, 'pca__whiten': True, 'svc__C': 0.7937005259840997, 'svc__gamma': 0.01687593342019228, 'svc__kernel': 'rbf'}\n",
      "-------------------\n",
      "Gridsearch CV for svm\n",
      "Best score using svm: 0.5898550724637682\n",
      "Total time: 279.244442 second\n",
      "EEG_ftrs_BVP \n",
      " {'pca__n_components': 105, 'pca__random_state': 9999, 'pca__whiten': False, 'svc__C': 9.332232316608927, 'svc__gamma': 0.0078125, 'svc__kernel': 'rbf'}\n",
      "-------------------\n",
      "Gridsearch CV for rf\n",
      "Best score using rf: 0.5688405797101449\n",
      "Total time: 411.690813 second\n",
      "EEG_ftrs_BVP \n",
      " {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 96, 'random_state': 75}\n",
      "-------------------\n",
      "Gridsearch CV for svm\n",
      "Best score using svm: 0.6021739130434783\n",
      "Total time: 265.010356 second\n",
      "EEG_ftrs_EDA \n",
      " {'pca__n_components': 196, 'pca__random_state': 9999, 'pca__whiten': False, 'svc__C': 9.332232316608927, 'svc__gamma': 0.0078125, 'svc__kernel': 'rbf'}\n",
      "-------------------\n",
      "Gridsearch CV for rf\n",
      "Best score using rf: 0.5746376811594203\n",
      "Total time: 437.738780 second\n",
      "EEG_ftrs_EDA \n",
      " {'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 82, 'random_state': 1}\n",
      "-------------------\n",
      "Gridsearch CV for svm\n",
      "Best score using svm: 0.610144927536232\n",
      "Total time: 311.386696 second\n",
      "EEG_ftrs_personality \n",
      " {'pca__n_components': 133, 'pca__random_state': 9999, 'pca__whiten': False, 'svc__C': 9.332232316608927, 'svc__gamma': 0.0078125, 'svc__kernel': 'rbf'}\n",
      "-------------------\n",
      "Gridsearch CV for rf\n",
      "Best score using rf: 0.5775362318840579\n",
      "Total time: 469.521788 second\n",
      "EEG_ftrs_personality \n",
      " {'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 86, 'random_state': 49}\n",
      "-------------------\n",
      "Gridsearch CV for svm\n",
      "Best score using svm: 0.4608695652173913\n",
      "Total time: 100.634066 second\n",
      "BVP_EDA \n",
      " {'pca__n_components': 11, 'pca__random_state': 9999, 'pca__whiten': True, 'svc__C': 9.332232316608927, 'svc__gamma': 0.7937005259840999, 'svc__kernel': 'rbf'}\n",
      "-------------------\n",
      "Gridsearch CV for svm\n",
      "Best score using svm: 0.47826086956521735\n",
      "Total time: 100.344124 second\n",
      "BVP_personality \n",
      " {'pca__n_components': 7, 'pca__random_state': 9999, 'pca__whiten': False, 'svc__C': 2.7215800003487542, 'svc__gamma': 1.7144879657061467, 'svc__kernel': 'rbf'}\n",
      "-------------------\n",
      "Gridsearch CV for svm\n",
      "Best score using svm: 0.4550724637681159\n",
      "Total time: 88.563776 second\n",
      "EDA_personality \n",
      " {'pca__n_components': 2, 'pca__random_state': 9999, 'pca__whiten': True, 'svc__C': 2.7215800003487542, 'svc__gamma': 0.0078125, 'svc__kernel': 'rbf'}\n",
      "-------------------\n",
      "Gridsearch CV for svm\n",
      "Best score using svm: 0.591304347826087\n",
      "Total time: 271.188042 second\n",
      "EEG_ftrs_BVP_EDA \n",
      " {'pca__n_components': 181, 'pca__random_state': 9999, 'pca__whiten': False, 'svc__C': 17.280955822276894, 'svc__gamma': 0.0078125, 'svc__kernel': 'rbf'}\n",
      "-------------------\n",
      "Gridsearch CV for rf\n",
      "Best score using rf: 0.5695652173913044\n",
      "Total time: 440.973620 second\n",
      "EEG_ftrs_BVP_EDA \n",
      " {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 43, 'random_state': 98}\n",
      "-------------------\n",
      "Gridsearch CV for svm\n",
      "Best score using svm: 0.5934782608695651\n",
      "Total time: 313.595233 second\n",
      "EEG_ftrs_BVP_personality \n",
      " {'pca__n_components': 94, 'pca__random_state': 9999, 'pca__whiten': False, 'svc__C': 9.332232316608927, 'svc__gamma': 0.0078125, 'svc__kernel': 'rbf'}\n",
      "-------------------\n",
      "Gridsearch CV for rf\n",
      "Best score using rf: 0.572463768115942\n",
      "Total time: 496.199708 second\n",
      "EEG_ftrs_BVP_personality \n",
      " {'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 98, 'random_state': 72}\n",
      "-------------------\n",
      "Gridsearch CV for svm\n",
      "Best score using svm: 0.6130434782608696\n",
      "Total time: 330.364335 second\n",
      "EEG_ftrs_EDA_personality \n",
      " {'pca__n_components': 231, 'pca__random_state': 9999, 'pca__whiten': False, 'svc__C': 17.280955822276894, 'svc__gamma': 0.0078125, 'svc__kernel': 'rbf'}\n",
      "-------------------\n",
      "Gridsearch CV for rf\n",
      "Best score using rf: 0.5695652173913044\n",
      "Total time: 449.726995 second\n",
      "EEG_ftrs_EDA_personality \n",
      " {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 68, 'random_state': 38}\n",
      "-------------------\n",
      "Gridsearch CV for svm\n",
      "Best score using svm: 0.47826086956521735\n",
      "Total time: 105.103159 second\n",
      "BVP_EDA_personality \n",
      " {'pca__n_components': 8, 'pca__random_state': 9999, 'pca__whiten': False, 'svc__C': 5.039684199579492, 'svc__gamma': 1.7144879657061467, 'svc__kernel': 'rbf'}\n",
      "-------------------\n",
      "Gridsearch CV for svm\n",
      "Best score using svm: 0.5934782608695652\n",
      "Total time: 338.625898 second\n",
      "EEG_ftrs_BVP_EDA_personality \n",
      " {'pca__n_components': 134, 'pca__random_state': 9999, 'pca__whiten': False, 'svc__C': 9.332232316608927, 'svc__gamma': 0.0078125, 'svc__kernel': 'rbf'}\n",
      "-------------------\n",
      "Gridsearch CV for rf\n",
      "Best score using rf: 0.5775362318840579\n",
      "Total time: 464.230583 second\n",
      "EEG_ftrs_BVP_EDA_personality \n",
      " {'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 87, 'random_state': 32}\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "save_folder = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "# save_folder = 'tmp'\n",
    "save_path = os.path.join('/home/nghia/PR_LAB/KERC_Chall/kerc2021/KERC21Baseline/KERC21Baseline/train_logs', save_folder)\n",
    "\n",
    "print('Save folder: ', os.path.join(save_path, save_folder))\n",
    "\n",
    "os.makedirs('/home/nghia/PR_LAB/KERC_Chall/kerc2021/KERC21Baseline/KERC21Baseline/train_logs', exist_ok=True)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "shutil.copy2('trad.py', save_path)\n",
    "\n",
    "dataset = load_data('/home/nghia/PR_LAB/KERC_Chall/kerc2021/KERC21Dataset/KERC21Dataset/preprocessed')\n",
    "\n",
    "full_feat_list = ['EEG_ftrs', 'BVP', 'EDA', 'personality']\n",
    "\n",
    "list_train_probas = []\n",
    "list_test_probas = []\n",
    "test_id = None\n",
    "\n",
    "for num_comb_feat in range(1, len(full_feat_list) + 1):\n",
    "    for subset in itertools.combinations(full_feat_list, num_comb_feat):\n",
    "        dataset_sel_feat = select_feat_type(dataset, feat_list=subset)\n",
    "        x_train, y_train = dataset_sel_feat['train']['feat'], dataset_sel_feat['train']['label']\n",
    "        x_test = dataset_sel_feat['test']['feat']\n",
    "        test_id = dataset_sel_feat['test']['id']\n",
    "        postfix = '_'.join(x for x in subset)\n",
    "\n",
    "        if not (num_comb_feat == 1 and 'personality' in subset):\n",
    "            # Use SVM in all the case except when only personality\n",
    "            clf_svm = gridsearch_clf(x_train, y_train, model_name='svm')\n",
    "            dump(clf_svm, os.path.join(save_path, 'clf_svm_{}.joblib'.format(postfix)))\n",
    "            y_test_svm = clf_svm.predict(x_test)\n",
    "            prediction_2_csv(y_test_svm, dataset_sel_feat['test']['id'], os.path.join(save_path, 'test_pred_svm_{}.csv'.format(postfix)))\n",
    "\n",
    "            if clf_svm.best_score_ >= 0.55:\n",
    "                list_train_probas.append(clf_svm.predict_proba(x_train))\n",
    "                list_test_probas.append(clf_svm.predict_proba(x_test))\n",
    "\n",
    "            with open(os.path.join(save_path, 'logs.txt'), 'a+') as fd:\n",
    "                fd.write('-----------------------------------------------\\n')\n",
    "                fd.write('SVM {}: {}\\n'.format(postfix, clf_svm.best_score_))\n",
    "                fd.write(str(clf_svm.best_params_))\n",
    "                print(postfix, '\\n', clf_svm.best_params_)\n",
    "\n",
    "        if 'EEG_ftrs' in subset:\n",
    "            # Use random forest whenever EEG_ftrs in list of features to be used\n",
    "            clf_rf = gridsearch_clf(x_train, y_train, model_name='rf')\n",
    "            dump(clf_rf, os.path.join(save_path, 'clf_rf_{}.joblib'.format(postfix)))\n",
    "            y_test_rf = clf_rf.predict(x_test)\n",
    "            prediction_2_csv(y_test_rf, dataset_sel_feat['test']['id'], os.path.join(save_path, 'test_pred_rf_{}.csv'.format(postfix)))\n",
    "\n",
    "            if clf_rf.best_score_ > 0.55:\n",
    "                list_train_probas.append(clf_rf.predict_proba(x_train))\n",
    "                list_test_probas.append(clf_rf.predict_proba(x_test))\n",
    "\n",
    "            with open(os.path.join(save_path, 'logs.txt'), 'a+') as fd:\n",
    "                fd.write('-----------------------------------------------\\n')\n",
    "                fd.write('RF {}: {}\\n'.format(postfix, clf_rf.best_score_))\n",
    "                fd.write(str(clf_rf.best_params_))\n",
    "                fd.write('\\n')\n",
    "                print(postfix, '\\n', clf_rf.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_comb_feat\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#subset\n",
    "x_train\n",
    "#y_train\n",
    "x_test\n",
    "#test_id\n",
    "#postfix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models to be averaging:  16\n",
      "Avg train F1-score:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Number of models to be averaging: ', len(list_train_probas))\n",
    "list_train_probas = np.stack(list_train_probas)\n",
    "avg_train_probas = np.mean(list_train_probas, axis=0)\n",
    "avg_train_preds = np.argmax(avg_train_probas, axis=1)\n",
    "print('Avg train F1-score: ', f1_score(y_true=y_train, y_pred=avg_train_preds, average='micro'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[0.07073006, 0.10122745, 0.76477537, 0.06326713],\n        [0.02269246, 0.80163304, 0.12269835, 0.05297615],\n        [0.0417527 , 0.81032509, 0.10983912, 0.03808309],\n        ...,\n        [0.02477591, 0.79581555, 0.11864011, 0.06076843],\n        [0.03248794, 0.12136428, 0.78518188, 0.0609659 ],\n        [0.01057916, 0.80624254, 0.12066934, 0.06250896]],\n\n       [[0.02020202, 0.2020202 , 0.74747475, 0.03030303],\n        [0.        , 0.80808081, 0.17171717, 0.02020202],\n        [0.03030303, 0.77777778, 0.14141414, 0.05050505],\n        ...,\n        [0.        , 0.81818182, 0.16161616, 0.02020202],\n        [0.01010101, 0.11111111, 0.78787879, 0.09090909],\n        [0.01010101, 0.75757576, 0.17171717, 0.06060606]],\n\n       [[0.05330305, 0.10536141, 0.78401518, 0.05732036],\n        [0.01873793, 0.8148416 , 0.11717211, 0.04924836],\n        [0.05208481, 0.82014341, 0.09929172, 0.02848006],\n        ...,\n        [0.02124357, 0.81108496, 0.115092  , 0.05257948],\n        [0.03200564, 0.1086134 , 0.79714418, 0.06223679],\n        [0.00906055, 0.70646731, 0.19814958, 0.08632257]],\n\n       ...,\n\n       [[0.07352941, 0.19117647, 0.72058824, 0.01470588],\n        [0.        , 0.70588235, 0.25      , 0.04411765],\n        [0.08823529, 0.72058824, 0.10294118, 0.08823529],\n        ...,\n        [0.01470588, 0.77941176, 0.16176471, 0.04411765],\n        [0.02941176, 0.11764706, 0.79411765, 0.05882353],\n        [0.        , 0.73529412, 0.19117647, 0.07352941]],\n\n       [[0.0462557 , 0.09345234, 0.81011123, 0.05018073],\n        [0.01635507, 0.84318409, 0.09837538, 0.04208545],\n        [0.04540936, 0.84501524, 0.08244276, 0.02713264],\n        ...,\n        [0.01966644, 0.84092137, 0.09743406, 0.04197813],\n        [0.02988925, 0.08774563, 0.80842921, 0.07393591],\n        [0.00744787, 0.8032745 , 0.12973247, 0.05954515]],\n\n       [[0.04597701, 0.12643678, 0.8045977 , 0.02298851],\n        [0.        , 0.82758621, 0.11494253, 0.05747126],\n        [0.        , 0.73563218, 0.17241379, 0.09195402],\n        ...,\n        [0.        , 0.90804598, 0.09195402, 0.        ],\n        [0.01149425, 0.08045977, 0.85057471, 0.05747126],\n        [0.01149425, 0.79310345, 0.12643678, 0.06896552]]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_train_probas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "list_test_probas = np.stack(list_test_probas)\n",
    "avg_test_probas = np.mean(list_test_probas, axis=0)\n",
    "avg_test_preds = np.argmax(avg_test_probas, axis=1)\n",
    "prediction_2_csv(avg_test_preds, test_id, os.path.join(save_path, 'test_pred_avg_{}.csv'.format('all_models')))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}